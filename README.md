# Taxi Order Prediction for Sweet Lift Taxi Company

This repository contains a machine learning project aimed at predicting the number of taxi orders for the next hour. The goal is to help the Sweet Lift Taxi company attract more drivers during peak hours by providing accurate predictions.

## Project Description

Sweet Lift Taxi company has collected historical data on taxi orders at airports. To attract more drivers during peak hours, we need to predict the number of taxi orders for the next hour. The goal is to build a model that achieves an RMSE metric of no more than 48 on the test set.

## Dataset

The dataset is stored in the `taxi.csv` file and contains the following fields:
- `datetime`: the timestamp of the orders
- `num_orders`: the number of taxi orders

## Project Structure

1. **Preparation**
    ```python
    import pandas as pd

    file_path = '/datasets/taxi.csv' 
    data = pd.read_csv(file_path, index_col='datetime', parse_dates=True)

    data_resampled = data.resample('H').sum()
    data_resampled.head()
    ```

2. **Exploratory Data Analysis (EDA)**
    ```python
    import matplotlib.pyplot as plt

    # Plotting the data
    data_resampled.plot(figsize=(12, 6))
    plt.title('Hourly Taxi Orders')
    plt.xlabel('Date')
    plt.ylabel('Number of Orders')
    plt.show()
    ```

3. **Feature Engineering and Training**
    ```python
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error

    data_resampled['hour'] = data_resampled.index.hour

    # Create lag features
    for lag in range(1, 4):  # You can change the range based on your model's performance
        data_resampled[f'lag_{lag}'] = data_resampled['num_orders'].shift(lag)

    # Drop rows with NaN values that were created by shifting
    data_resampled.dropna(inplace=True)

    features = data_resampled.drop('num_orders', axis=1)
    target = data_resampled['num_orders']

    train_features, test_features, train_target, test_target = train_test_split(
        features, target, test_size=0.1, shuffle=False)

    model = RandomForestRegressor(n_estimators=100, random_state=123)
    model.fit(train_features, train_target)

    train_predictions = model.predict(train_features)
    test_predictions = model.predict(test_features)
    print("Training RMSE:", mean_squared_error(train_target, train_predictions, squared=False))
    print("Test RMSE:", mean_squared_error(test_target, test_predictions, squared=False))
    ```

4. **Testing and Improved Feature Engineering**
    ```python
    # Feature engineering: Add day of the week and rolling mean
    data_resampled['day_of_week'] = data_resampled.index.dayofweek
    data_resampled['rolling_mean_3h'] = data_resampled['num_orders'].rolling(window=3).mean()

    # Remove NaN values generated by rolling mean
    data_resampled.dropna(inplace=True)

    # Update feature and target variable assignments
    features = data_resampled.drop('num_orders', axis=1)
    target = data_resampled['num_orders']

    train_features, test_features, train_target, test_target = train_test_split(
        features, target, test_size=0.1, shuffle=False)

    model = RandomForestRegressor(n_estimators=150, max_depth=10, random_state=123)
    model.fit(train_features, train_target)

    train_predictions = model.predict(train_features)
    test_predictions = model.predict(test_features)
    print("Training RMSE:", mean_squared_error(train_target, train_predictions, squared=False))
    print("Test RMSE:", mean_squared_error(test_target, test_predictions, squared=False))
    ```

5. **Results**
    - Initial Model:
        - Training RMSE: 9.36
        - Test RMSE: 55.42
    - Improved Model:
        - Training RMSE: 4.46
        - Test RMSE: 29.31

6. **Conclusion**
    The improved model using RandomForestRegressor with additional features (day of the week and rolling mean) achieved a Training RMSE of 4.46 and a Test RMSE of 29.31, which is well within the target RMSE of 48. This demonstrates the effectiveness of feature engineering and hyperparameter tuning in improving model performance.

## Instructions to Run the Project

1. Clone the repository:
    ```bash
    git clone <repository-url>
    cd <repository-folder>
    ```

2. Install the required libraries:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the notebook or script:
    ```bash
    jupyter notebook Taxi_Order_Prediction.ipynb
    ```

## Future Work

- Experiment with additional machine learning models like XGBoost and LSTM.
- Perform hyperparameter tuning using grid search or random search.
- Incorporate additional external data (e.g., weather conditions, holiday schedules) to improve prediction accuracy.

---

Feel free to contribute to this project by submitting a pull request or opening an issue for any bugs or improvements.
